{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 한글 폰트 설정\n",
    "import matplotlib\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "if platform.system() == \"Windows\":\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "elif platform.system()==\"Darwin\":\n",
    "    rc('font', family='AppleGothic')\n",
    "else:\n",
    "    print(\"Unknown System\")\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일반 회귀 모델 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]]), array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\", 'C:\\\\Users\\\\Jongho\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df_boston['target'] = pd.Series(boston.target)\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순선형 회귀, 다중선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel = ['INDUS', 'RM']\n",
    "sel = df_boston.columns[:-1]\n",
    "X = df_boston[sel] # 집 값에 영향 주는 \n",
    "y = df_boston['target'] # 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 나누기\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.83885359, 36.00783288, 15.08324755, 25.23090886, 18.87864064,\n",
       "       23.21398327, 17.5931124 , 14.30508093, 23.05438985, 20.62008346,\n",
       "       24.78514683, 18.66833668, -6.9788951 , 21.83575737, 19.20898992,\n",
       "       26.2868054 , 20.54379176,  5.65713224, 40.42358065, 17.64146116,\n",
       "       27.32258958, 30.05056174, 11.15013704, 24.11530393, 17.89145648,\n",
       "       15.79348591, 22.94743453, 14.2586068 , 22.26731194, 19.24709013,\n",
       "       22.26897546, 25.24344002, 25.69165643, 17.98759507, 16.70286649,\n",
       "       17.11631225, 31.19643534, 20.17835831, 23.71828436, 24.79196868,\n",
       "       13.94575895, 32.00389982, 42.53869791, 17.44523722, 27.15354457,\n",
       "       17.07482215, 13.89272021, 26.06440323, 20.36888769, 29.97813037,\n",
       "       21.35346608, 34.32287916, 15.88498671, 26.17757739, 39.50970314,\n",
       "       22.84123308, 18.95049088, 32.68913818, 25.02057949, 12.90539147,\n",
       "       22.76052302, 30.53884316, 31.60797905, 15.92162168, 20.50670563,\n",
       "       16.50798147, 20.50202198, 26.00723901, 30.63860954, 11.42877835,\n",
       "       20.53765181, 27.56249175, 10.85162601, 15.96871769, 23.87570192,\n",
       "        5.66369672, 21.47818991, 41.2820034 , 18.56559986,  9.08857252,\n",
       "       20.97848452, 13.0630057 , 20.99054395,  9.34050291, 23.13686588,\n",
       "       31.80106627, 19.10245917, 25.59186169, 29.14490119, 20.17571514,\n",
       "       25.5962149 ,  5.20301905, 20.16835681, 15.08546746, 12.8601543 ,\n",
       "       20.80904894, 24.68556943, -0.77450939, 13.33875673, 15.62703156,\n",
       "       22.21755358, 24.58188737, 10.77302163, 19.50068376, 23.23450396,\n",
       "       11.77388822, 18.36777924, 25.4383785 , 20.89079232, 24.08440617,\n",
       "        7.3658717 , 19.16424347, 21.93734133, 27.41191713, 32.50857196,\n",
       "       14.86885244, 35.05912525, 12.86075113, 20.83043572, 28.42077138,\n",
       "       15.65853688, 24.67196362,  3.28420892, 23.79879617, 25.73329894,\n",
       "       23.04815612, 24.73046824])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.28322638e-01  2.95517751e-02  4.88590934e-02  2.77350326e+00\n",
      " -1.62388292e+01  4.36875476e+00 -9.24808158e-03 -1.40086668e+00\n",
      "  2.57761243e-01 -9.95694820e-03 -9.23122944e-01  1.31854199e-02\n",
      " -5.17639519e-01]\n",
      "29.83642016383913\n"
     ]
    }
   ],
   "source": [
    "# y = (-0.6341 * INDUS)+ (8.16489603*RM) + 29.959\n",
    "print(model.coef_) # w1\n",
    "print(model.intercept_) # b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_X = PolynomialFeatures(degree=2,\n",
    "         include_bias=False).fit_transform(X)  # 데이터 feature 추가 생성\n",
    "ex_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.78\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ex_X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"훈련 데이터 세트 점수 : {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 세트 점수 : {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라쏘(Lasso) - L1, 릿지(Ridge) - L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = df_boston.columns[:-1]\n",
    "X = df_boston[sel] # 집 값에 영향 주는 \n",
    "y = df_boston['target'] # 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape) # 특징의 개수\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화, 추가 생성 :  (506, 104) (506,)\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalize_X = MinMaxScaler().fit_transform(X)  # 입력 데이터 정규화\n",
    "ex_X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(normalize_X)  # 데이터 feature 추가 생성\n",
    "\n",
    "print(\"정규화, 추가 생성 : \", ex_X.shape, y.shape)\n",
    "print(np.min(ex_X),np.max(ex_X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(ex_X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"훈련 데이터 세트 점수 : {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 세트 점수 : {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 세트 점수 : 0.89\n",
      "테스트 데이터 세트 점수 : 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jongho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.848133364149362, tolerance: 3.361037625329815\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge # Lasso : L1, Ridge: L2\n",
    "lasso = Lasso(alpha=0.01).fit(X_train, y_train)\n",
    "print(\"학습용 데이터 세트 점수 : {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 세트 점수 : {:.2f}\".format(lasso.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 세트 점수 : 0.92\n",
      "테스트 데이터 세트 점수 : 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge # Lasso : L1, Ridge: L2\n",
    "ridge = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"학습용 데이터 세트 점수 : {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 세트 점수 : {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4-5 (추가) 최적의 alpha를 찾아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 세트 점수 : 0.77\n",
      "테스트 데이터 세트 점수 : 0.73\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.80\n",
      "테스트 데이터 세트 점수 : 0.76\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.87\n",
      "테스트 데이터 세트 점수 : 0.81\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.89\n",
      "테스트 데이터 세트 점수 : 0.82\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.92\n",
      "테스트 데이터 세트 점수 : 0.82\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.81\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.81\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sel = [10, 5, 1, 0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "for var in sel:\n",
    "    ridge = Ridge(alpha=var).fit(X_train, y_train)\n",
    "    print(\"학습용 데이터 세트 점수 : {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "    print(\"테스트 데이터 세트 점수 : {:.2f}\".format(ridge.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 세트 점수 : 0.00\n",
      "테스트 데이터 세트 점수 : -0.03\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.00\n",
      "테스트 데이터 세트 점수 : -0.03\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.27\n",
      "테스트 데이터 세트 점수 : 0.26\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.61\n",
      "테스트 데이터 세트 점수 : 0.58\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.75\n",
      "테스트 데이터 세트 점수 : 0.70\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.89\n",
      "테스트 데이터 세트 점수 : 0.80\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.93\n",
      "테스트 데이터 세트 점수 : 0.81\n",
      "\n",
      "학습용 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jongho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.848133364149362, tolerance: 3.361037625329815\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jongho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 864.3796550250048, tolerance: 3.361037625329815\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jongho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1061.5581359471444, tolerance: 3.361037625329815\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "sel = [10, 5, 1, 0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "for var in sel:\n",
    "    lasso = Lasso(alpha=var).fit(X_train, y_train)\n",
    "    print(\"학습용 데이터 세트 점수 : {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "    print(\"테스트 데이터 세트 점수 : {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear 학습 :  0.9448313975211594\n",
      "Linear 테스트 :  0.7758378393351691\n",
      "Ridge 학습 :  0.8700969775259919\n",
      "Ridge 테스트 :  0.8145421818415556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2000.0, 2000.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LinearRegression \n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Linear 학습 : \", lr.score(X_train, y_train) )\n",
    "print(\"Linear 테스트 : \", lr.score(X_test, y_test) )\n",
    "\n",
    "# Ridge - L2규제, 0에 가깝게 만들지만, 0이 되는 친구는 없다.\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"Ridge 학습 : \", ridge.score(X_train, y_train) )\n",
    "print(\"Ridge 테스트 : \", ridge.score(X_test, y_test) )\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hlines(0,0, len(lr.coef_))\n",
    "plt.plot(lr.coef_, 's', label=\"LinearRegression\")\n",
    "plt.title('LinearRegression')\n",
    "plt.ylim(-2000,2000)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hlines(0,0, len(lr.coef_))\n",
    "plt.plot(ridge.coef_, 's', label=\"Ridge\")\n",
    "plt.title('Ridge')\n",
    "plt.ylim(-2000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge - L2규제 : 0에 가깝게 만들지만, 0인 값은 없다.\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "\n",
    "print('학습:' , ridge.score(X_train, y_train))\n",
    "print('테스트:' , ridge.score(X_test, y_test))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 테스트 데이터가 높고 , 학습과의 차이가 많이 나지 않아야 좋은 성능이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
